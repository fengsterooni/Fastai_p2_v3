{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Link](https://github.com/fastai/course-v3/blob/master/nbs/swift/00_load_data.ipynb) to the original notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing packages:\n",
      "\t.package(url: \"https://github.com/mxcl/Path.swift\", from: \"0.16.1\")\n",
      "\t\tPath\n",
      "\t.package(url: \"https://github.com/saeta/Just\", from: \"0.7.2\")\n",
      "\t\tJust\n",
      "\t.package(url: \"https://github.com/latenitesoft/NotebookExport\", from: \"0.5.0\")\n",
      "\t\tNotebookExport\n",
      "With SwiftPM flags: []\n",
      "Working in: /tmp/tmpb_7x4typ/swift-install\n",
      "[1/2] Compiling jupyterInstalledPackages jupyterInstalledPackages.swift\n",
      "[2/3] Merging module jupyterInstalledPackages\n",
      "Initializing Swift...\n",
      "Installation complete!\n"
     ]
    }
   ],
   "source": [
    "%install-location $cwd/swift-install\n",
    "%install '.package(url: \"https://github.com/mxcl/Path.swift\", from: \"0.16.1\")' Path\n",
    "%install '.package(url: \"https://github.com/saeta/Just\", from: \"0.7.2\")' Just\n",
    "%install '.package(url: \"https://github.com/latenitesoft/NotebookExport\", from: \"0.5.0\")' NotebookExport"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define custom operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "// export\n",
    "precedencegroup ExponentiationPrecedence {\n",
    "    associativity: right\n",
    "    higherThan: MultiplicationPrecedence\n",
    "}\n",
    "infix operator ** : ExponentiationPrecedence\n",
    "\n",
    "precedencegroup CompositionPrecedence { associativity: left }\n",
    "infix operator >| : CompositionPrecedence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Infix**: \n",
    "Operator is used in between \"targets\"\n",
    "\n",
    "https://docs.swift.org/swift-book/LanguageGuide/AdvancedOperators.html\n",
    "\n",
    "\n",
    "**Precedence**: \n",
    "Defines precedence of the operator\n",
    "\n",
    "https://developer.apple.com/documentation/swift/swift_standard_library/operator_declarations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries\n",
    "\n",
    "- [Just](https://github.com/JustHTTP/Just) does the equivalent of requests in python\n",
    "- [Path](https://github.com/mxcl/Path.swift) is even better than its python counterpart\n",
    "- Foundation is the base library from Apple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "//export\n",
    "import Foundation\n",
    "import Just\n",
    "import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "//export\n",
    "public extension String {\n",
    "    @discardableResult\n",
    "    func shell(_ args: String...) -> String\n",
    "    {\n",
    "        let (task,pipe) = (Process(),Pipe())\n",
    "        task.executableURL = URL(fileURLWithPath: self)\n",
    "        (task.arguments,task.standardOutput) = (args,pipe)\n",
    "        do    { try task.run() }\n",
    "        catch { print(\"Unexpected error: \\(error).\") }\n",
    "\n",
    "        let data = pipe.fileHandleForReading.readDataToEndOfFile()\n",
    "        return String(data: data, encoding: String.Encoding.utf8) ?? \"\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**@discardableResult**\n",
    "\n",
    "Ignore return values.\n",
    "\n",
    "https://www.hackingwithswift.com/example-code/language/how-to-ignore-return-values-using-discardableresult\n",
    "\n",
    "\n",
    "**Process()**\n",
    "\n",
    "Process\n",
    "\n",
    "https://developer.apple.com/documentation/foundation/process\n",
    "\n",
    "\n",
    "**Pipe()**\n",
    "\n",
    "Pipe\n",
    "\n",
    "https://developer.apple.com/documentation/foundation/pipe\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 16K\r\n",
      "-rw-r--r-- 1 root root 3.0K Jul 30 20:58 00_load_data.ipynb\r\n",
      "-rw-r--r-- 1 1000 1000  225 Jul 30 20:22 README.md\r\n",
      "-rw-r--r-- 1 root root 3.4K Jul 30 18:02 hello_world.ipynb\r\n",
      "drwxr-xr-x 4 root root 4.0K Jul 30 18:00 swift-install\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "print(\"/bin/ls\".shell(\"-lh\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"[ls](https://www.rapidtables.com/code/linux/ls.html) -lh\" -> list long format with readable file size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 16\r\n",
      "-rw-r--r-- 1 root root 3071 Jul 30 20:58 00_load_data.ipynb\r\n",
      "-rw-r--r-- 1 1000 1000  225 Jul 30 20:22 README.md\r\n",
      "-rw-r--r-- 1 root root 3402 Jul 30 18:02 hello_world.ipynb\r\n",
      "drwxr-xr-x 4 root root 4096 Jul 30 18:00 swift-install\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "print(\"/bin/ls\".shell(\"-l\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "//export\n",
    "public func downloadFile(_ url: String, dest: String? = nil, force: Bool = false) {\n",
    "    let dest_name = dest ?? (Path.cwd/url.split(separator: \"/\").last!).string\n",
    "    let url_dest = URL(fileURLWithPath: (dest ?? (Path.cwd/url.split(separator: \"/\").last!).string))\n",
    "    if !force && Path(dest_name)!.exists { return }\n",
    "\n",
    "    print(\"Downloading \\(url)...\")\n",
    "\n",
    "    if let cts = Just.get(url).content {\n",
    "        do    {try cts.write(to: URL(fileURLWithPath:dest_name))}\n",
    "        catch {print(\"Can't write to \\(url_dest).\\n\\(error)\")}\n",
    "    } else {\n",
    "        print(\"Can't reach \\(url)\")\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://storage.googleapis.com/cvdf-datasets/mnist/train-images-idx3-ubyte.gz...\r\n"
     ]
    }
   ],
   "source": [
    "downloadFile(\"https://storage.googleapis.com/cvdf-datasets/mnist/train-images-idx3-ubyte.gz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here it comes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "//export\n",
    "import TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is generic over the element type on the return value. We could define two functions like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```swift\n",
    "func loadMNIST(training: Bool, labels: Bool, path: Path, flat: Bool) -> Tensor<Float> {}\n",
    "func loadMNIST(training: Bool, labels: Bool, path: Path, flat: Bool) -> Tensor<Int32> {}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "but that would be boring. So we make loadMNIST take a \"type parameter\" T which indicates what sort of element type to load a tensor into.\n",
    "\n",
    "\n",
    "But this doesn't work because S4TF can't just put any type of data inside a Tensor. We have to tell it that this type:\n",
    "\n",
    "is a type that TF can understand and deal with\n",
    "is a type that can be applied to the data we read in the byte format\n",
    "We do this by defining a protocol called ConvertibleFromByte that inherits from TensorFlowScalar. That takes care of the first requirement. The second requirement is dealt with by asking for an init method that takes UInt8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "//export\n",
    "protocol ConvertibleFromByte: TensorFlowScalar {\n",
    "    init(_ d:UInt8)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "//export\n",
    "extension Float : ConvertibleFromByte {}\n",
    "extension Int32 : ConvertibleFromByte {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "//export\n",
    "extension Data {\n",
    "    func asTensor<T:ConvertibleFromByte>() -> Tensor<T> {\n",
    "        return Tensor(map(T.init))\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "//export\n",
    "func loadMNIST<T: ConvertibleFromByte>\n",
    "            (training: Bool, labels: Bool, path: Path, flat: Bool) -> Tensor<T> {\n",
    "    let split = training ? \"train\" : \"t10k\"\n",
    "    let kind = labels ? \"labels\" : \"images\"\n",
    "    let batch = training ? 60000 : 10000\n",
    "    let shape: TensorShape = labels ? [batch] : (flat ? [batch, 784] : [batch, 28, 28])\n",
    "    let dropK = labels ? 8 : 16\n",
    "    let baseUrl = \"https://storage.googleapis.com/cvdf-datasets/mnist/\"\n",
    "    let fname = split + \"-\" + kind + \"-idx\\(labels ? 1 : 3)-ubyte\"\n",
    "    let file = path/fname\n",
    "    if !file.exists {\n",
    "        downloadFile(\"\\(baseUrl)\\(fname).gz\", dest:(path/\"\\(fname).gz\").string)\n",
    "        \"/bin/gunzip\".shell(\"-fq\", (path/\"\\(fname).gz\").string)\n",
    "    }\n",
    "    let data = try! Data(contentsOf: URL(fileURLWithPath: file.string)).dropFirst(dropK)\n",
    "    if labels { return data.asTensor() }\n",
    "    else      { return data.asTensor().reshaped(to: shape)}\n",
    "}\n",
    "\n",
    "public func loadMNIST(path:Path, flat:Bool = false)\n",
    "        -> (Tensor<Float>, Tensor<Int32>, Tensor<Float>, Tensor<Int32>) {\n",
    "    try! path.mkdir(.p)\n",
    "    return (\n",
    "        loadMNIST(training: true,  labels: false, path: path, flat: flat) / 255.0,\n",
    "        loadMNIST(training: true,  labels: true,  path: path, flat: flat),\n",
    "        loadMNIST(training: false, labels: false, path: path, flat: flat) / 255.0,\n",
    "        loadMNIST(training: false, labels: true,  path: path, flat: flat)\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "//export\n",
    "public let mnistPath = Path.home/\".fastai\"/\"data\"/\"mnist_tst\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://storage.googleapis.com/cvdf-datasets/mnist/train-images-idx3-ubyte.gz...\n",
      "Downloading https://storage.googleapis.com/cvdf-datasets/mnist/train-labels-idx1-ubyte.gz...\n",
      "Downloading https://storage.googleapis.com/cvdf-datasets/mnist/t10k-images-idx3-ubyte.gz...\n",
      "Downloading https://storage.googleapis.com/cvdf-datasets/mnist/t10k-labels-idx1-ubyte.gz...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "▿ [60000, 28, 28]\n",
       "  ▿ dimensions : 3 elements\n",
       "    - 0 : 60000\n",
       "    - 1 : 28\n",
       "    - 2 : 28\n"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "let (xTrain, yTrain, xValid, yValid) = loadMNIST(path: mnistPath)\n",
    "xTrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "▿ [60000, 784]\n",
       "  ▿ dimensions : 2 elements\n",
       "    - 0 : 60000\n",
       "    - 1 : 784\n"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "let (xTrain, yTrain, xValid, yValid) = loadMNIST(path: mnistPath, flat: true)\n",
    "xTrain.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "//export \n",
    "import Dispatch\n",
    "\n",
    "// ⏰Time how long it takes to run the specified function, optionally taking\n",
    "// the average across a number of repetitions.\n",
    "public func time(repeating: Int = 1, _ f: () -> ()) {\n",
    "    guard repeating > 0 else { return }\n",
    "    \n",
    "    // Warmup\n",
    "    if repeating > 1 { f() }\n",
    "    \n",
    "    var times = [Double]()\n",
    "    for _ in 1...repeating {\n",
    "        let start = DispatchTime.now()\n",
    "        f()\n",
    "        let end = DispatchTime.now()\n",
    "        let nanoseconds = Double(end.uptimeNanoseconds - start.uptimeNanoseconds)\n",
    "        let milliseconds = nanoseconds / 1e6\n",
    "        times.append(milliseconds)\n",
    "    }\n",
    "    print(\"average: \\(times.reduce(0.0, +)/Double(times.count)) ms,   \" +\n",
    "          \"min: \\(times.reduce(times[0], min)) ms,   \" +\n",
    "          \"max: \\(times.reduce(times[0], max)) ms\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average: 308.656734 ms,   min: 305.301622 ms,   max: 324.08724 ms\r\n"
     ]
    }
   ],
   "source": [
    "time(repeating: 10) {\n",
    "    _ = loadMNIST(training: false, labels: false, path: mnistPath, flat: false) as Tensor<Float>\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "// export\n",
    "public extension String {\n",
    "    func findFirst(pat: String) -> Range<String.Index>? {\n",
    "        return range(of: pat, options: .regularExpression)\n",
    "    }\n",
    "    func hasMatch(pat: String) -> Bool {\n",
    "        return findFirst(pat:pat) != nil\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "//export\n",
    "public func notebookToScript(fname: Path){\n",
    "    let newname = fname.basename(dropExtension: true)+\".swift\"\n",
    "    let url = fname.parent/\"FastaiNotebooks/Sources/FastaiNotebooks\"/newname\n",
    "    do {\n",
    "        let data = try Data(contentsOf: fname.url)\n",
    "        let jsonData = try JSONSerialization.jsonObject(with: data, options: .allowFragments) as! [String: Any]\n",
    "        let cells = jsonData[\"cells\"] as! [[String:Any]]\n",
    "        var module = \"\"\"\n",
    "/*\n",
    "THIS FILE WAS AUTOGENERATED! DO NOT EDIT!\n",
    "file to edit: \\(fname.lastPathComponent)\n",
    "\n",
    "*/\n",
    "        \n",
    "\"\"\"\n",
    "        for cell in cells {\n",
    "            if let source = cell[\"source\"] as? [String], !source.isEmpty, \n",
    "                   source[0].hasMatch(pat: #\"^\\s*//\\s*export\\s*$\"#) {\n",
    "                module.append(\"\\n\" + source[1...].joined() + \"\\n\")\n",
    "            }\n",
    "        }\n",
    "        try module.write(to: url, encoding: .utf8)\n",
    "    } catch {\n",
    "        print(\"Can't read the content of \\(fname)\")\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "// export\n",
    "public func exportNotebooks(_ path: Path) {\n",
    "    for entry in try! path.ls()\n",
    "    where entry.kind == Entry.Kind.file && \n",
    "          entry.path.basename().hasMatch(pat: #\"^\\d*_.*ipynb$\"#) {\n",
    "        print(\"Converting \\(entry)\")\n",
    "        notebookToScript(fname: entry.path)\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Can't read the content of /notebooks/fastai_p2_v3/00_load_data.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "notebookToScript(fname: Path.cwd/\"00_load_data.ipynb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success\r\n"
     ]
    }
   ],
   "source": [
    "import NotebookExport\n",
    "let exporter = NotebookExport(Path.cwd/\"00_load_data.ipynb\")\n",
    "print(exporter.export(usingPrefix: \"FastaiNotebook_\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Swift",
   "language": "swift",
   "name": "swift"
  },
  "language_info": {
   "file_extension": ".swift",
   "mimetype": "text/x-swift",
   "name": "swift",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
